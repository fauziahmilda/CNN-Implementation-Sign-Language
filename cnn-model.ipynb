{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'datasetASL-master\\datasetASL-master\\Dataset'\n",
    "target_size = (100,100)\n",
    "classes = 10\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./25,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=False,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(data_dir, target_size=target_size,\n",
    "                                              shuffle= True,\n",
    "                                              batch_size=32,\n",
    "                                              color_mode='rgb',\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='training')\n",
    "val_gen = train_datagen.flow_from_directory(data_dir,target_size=target_size,\n",
    "                                            batch_size=32,\n",
    "                                            color_mode='rgb',\n",
    "                                            class_mode='categorical',\n",
    "                                            subset='validation')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=3, strides=1, activation='relu', padding='same',input_shape=(100,100,3)))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=3, strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=2))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=3, strides=1, activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=1))\n",
    "\n",
    "#FLATTEN\n",
    "model.add(Flatten()) ##dibuat jadi satu dimensi\n",
    "model.add(Dropout(0.5)) ##dilakukan dropout\n",
    "model.add(Dense(512, activation='relu')) ##akan menjadi input fully connected\n",
    "model.add(Dense(classes, activation='softmax')) ##output ##pakesoftmax karena categorical\n",
    "\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "##memperlihatkan model yang dibuat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##melakukan compiling\n",
    "epochs = 7 # numer of forward an backward pass for each batch_size\n",
    "history = model.fit_generator(train_gen, epochs=epochs, validation_data=val_gen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as file:\n",
    "    file.write(model_json)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"SUCCESSFULL model is SAVED !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
